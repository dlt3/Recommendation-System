{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "authentic-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as ppp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import mlxtend\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "verbal-brother",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "#데이터셋 생성\n",
    "# 우유A 양상추B 기저귀C 주스D 맥주E\n",
    "\n",
    "\n",
    "data = np.array([\n",
    "    ['A', 'B', 'C'],\n",
    "    ['B', 'C', 'E'],\n",
    "    ['A', 'B', 'C', 'E'],\n",
    "    ['B', 'E']\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-transformation",
   "metadata": {},
   "source": [
    "#### Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "exterior-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "stainless-bridal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B      C      E\n",
       "0   True  True   True  False\n",
       "1  False  True   True   True\n",
       "2   True  True   True   True\n",
       "3  False  True  False   True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "tribal-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.18 ms, sys: 4.06 ms, total: 12.2 ms\n",
      "Wall time: 25 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(A, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(A, C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(C, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(E, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(E, C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, A, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, B, E)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support   itemsets\n",
       "0      0.50        (A)\n",
       "1      1.00        (B)\n",
       "2      0.75        (C)\n",
       "3      0.75        (E)\n",
       "4      0.50     (A, B)\n",
       "5      0.50     (A, C)\n",
       "6      0.75     (C, B)\n",
       "7      0.75     (E, B)\n",
       "8      0.50     (E, C)\n",
       "9      0.50  (C, A, B)\n",
       "10     0.50  (C, B, E)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from mlxtend.frequent_patterns import apriori\n",
    "apriori(df, min_support=0.5, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-layout",
   "metadata": {},
   "source": [
    "#### FP-Growth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "removed-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "genetic-madrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B      C      E\n",
       "0   True  True   True  False\n",
       "1  False  True   True   True\n",
       "2   True  True   True   True\n",
       "3  False  True  False   True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "warming-bottom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 ms, sys: 0 ns, total: 2.04 ms\n",
      "Wall time: 1.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(C, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(E, C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, B, E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(A, C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(A, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, A, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(E, B)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support   itemsets\n",
       "0      1.00        (B)\n",
       "1      0.75        (C)\n",
       "2      0.50        (A)\n",
       "3      0.75        (E)\n",
       "4      0.75     (C, B)\n",
       "5      0.50     (E, C)\n",
       "6      0.50  (C, B, E)\n",
       "7      0.50     (A, C)\n",
       "8      0.50     (A, B)\n",
       "9      0.50  (C, A, B)\n",
       "10     0.75     (E, B)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "fpgrowth(df, min_support=0.5, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "gorgeous-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "liquid-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(C)</td>\n",
       "      <td>(B)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(B)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(E)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(C)</td>\n",
       "      <td>(E)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(C, B)</td>\n",
       "      <td>(E)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(E, C)</td>\n",
       "      <td>(B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(E, B)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(C)</td>\n",
       "      <td>(E, B)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(B)</td>\n",
       "      <td>(E, C)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(E)</td>\n",
       "      <td>(C, B)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(C)</td>\n",
       "      <td>(A)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(B)</td>\n",
       "      <td>(A)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(E)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(A, C)</td>\n",
       "      <td>(B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(C, B)</td>\n",
       "      <td>(A)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(A, B)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(C)</td>\n",
       "      <td>(A, B)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(C, B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(B)</td>\n",
       "      <td>(A, C)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(E, A)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(E, C)</td>\n",
       "      <td>(A)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(A, C)</td>\n",
       "      <td>(E)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(E, C)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(E, A)</td>\n",
       "      <td>(B)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(A, B)</td>\n",
       "      <td>(E)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(E, B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(A, C, B)</td>\n",
       "      <td>(E)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(E, A, C)</td>\n",
       "      <td>(B)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(E, C, B)</td>\n",
       "      <td>(A)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(E, A, B)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(A, C)</td>\n",
       "      <td>(E, B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(E, C)</td>\n",
       "      <td>(A, B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(A, B)</td>\n",
       "      <td>(E, C)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(E, A)</td>\n",
       "      <td>(C, B)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(E, C, B)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(E)</td>\n",
       "      <td>(B)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(B)</td>\n",
       "      <td>(E)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support  support  \\\n",
       "0          (C)         (B)                0.75                1.00     0.75   \n",
       "1          (B)         (C)                1.00                0.75     0.75   \n",
       "2          (E)         (C)                0.75                0.75     0.50   \n",
       "3          (C)         (E)                0.75                0.75     0.50   \n",
       "4       (C, B)         (E)                0.75                0.75     0.50   \n",
       "5       (E, C)         (B)                0.50                1.00     0.50   \n",
       "6       (E, B)         (C)                0.75                0.75     0.50   \n",
       "7          (C)      (E, B)                0.75                0.75     0.50   \n",
       "8          (B)      (E, C)                1.00                0.50     0.50   \n",
       "9          (E)      (C, B)                0.75                0.75     0.50   \n",
       "10         (A)         (C)                0.50                0.75     0.50   \n",
       "11         (C)         (A)                0.75                0.50     0.50   \n",
       "12         (A)         (B)                0.50                1.00     0.50   \n",
       "13         (B)         (A)                1.00                0.50     0.50   \n",
       "14         (A)         (E)                0.50                0.75     0.25   \n",
       "15      (A, C)         (B)                0.50                1.00     0.50   \n",
       "16      (C, B)         (A)                0.75                0.50     0.50   \n",
       "17      (A, B)         (C)                0.50                0.75     0.50   \n",
       "18         (C)      (A, B)                0.75                0.50     0.50   \n",
       "19         (A)      (C, B)                0.50                0.75     0.50   \n",
       "20         (B)      (A, C)                1.00                0.50     0.50   \n",
       "21      (E, A)         (C)                0.25                0.75     0.25   \n",
       "22      (E, C)         (A)                0.50                0.50     0.25   \n",
       "23      (A, C)         (E)                0.50                0.75     0.25   \n",
       "24         (A)      (E, C)                0.50                0.50     0.25   \n",
       "25      (E, A)         (B)                0.25                1.00     0.25   \n",
       "26      (A, B)         (E)                0.50                0.75     0.25   \n",
       "27         (A)      (E, B)                0.50                0.75     0.25   \n",
       "28   (A, C, B)         (E)                0.50                0.75     0.25   \n",
       "29   (E, A, C)         (B)                0.25                1.00     0.25   \n",
       "30   (E, C, B)         (A)                0.50                0.50     0.25   \n",
       "31   (E, A, B)         (C)                0.25                0.75     0.25   \n",
       "32      (A, C)      (E, B)                0.50                0.75     0.25   \n",
       "33      (E, C)      (A, B)                0.50                0.50     0.25   \n",
       "34      (A, B)      (E, C)                0.50                0.50     0.25   \n",
       "35      (E, A)      (C, B)                0.25                0.75     0.25   \n",
       "36         (A)   (E, C, B)                0.50                0.50     0.25   \n",
       "37         (E)         (B)                0.75                1.00     0.75   \n",
       "38         (B)         (E)                1.00                0.75     0.75   \n",
       "\n",
       "    confidence      lift  leverage  conviction  \n",
       "0     1.000000  1.000000    0.0000         inf  \n",
       "1     0.750000  1.000000    0.0000        1.00  \n",
       "2     0.666667  0.888889   -0.0625        0.75  \n",
       "3     0.666667  0.888889   -0.0625        0.75  \n",
       "4     0.666667  0.888889   -0.0625        0.75  \n",
       "5     1.000000  1.000000    0.0000         inf  \n",
       "6     0.666667  0.888889   -0.0625        0.75  \n",
       "7     0.666667  0.888889   -0.0625        0.75  \n",
       "8     0.500000  1.000000    0.0000        1.00  \n",
       "9     0.666667  0.888889   -0.0625        0.75  \n",
       "10    1.000000  1.333333    0.1250         inf  \n",
       "11    0.666667  1.333333    0.1250        1.50  \n",
       "12    1.000000  1.000000    0.0000         inf  \n",
       "13    0.500000  1.000000    0.0000        1.00  \n",
       "14    0.500000  0.666667   -0.1250        0.50  \n",
       "15    1.000000  1.000000    0.0000         inf  \n",
       "16    0.666667  1.333333    0.1250        1.50  \n",
       "17    1.000000  1.333333    0.1250         inf  \n",
       "18    0.666667  1.333333    0.1250        1.50  \n",
       "19    1.000000  1.333333    0.1250         inf  \n",
       "20    0.500000  1.000000    0.0000        1.00  \n",
       "21    1.000000  1.333333    0.0625         inf  \n",
       "22    0.500000  1.000000    0.0000        1.00  \n",
       "23    0.500000  0.666667   -0.1250        0.50  \n",
       "24    0.500000  1.000000    0.0000        1.00  \n",
       "25    1.000000  1.000000    0.0000         inf  \n",
       "26    0.500000  0.666667   -0.1250        0.50  \n",
       "27    0.500000  0.666667   -0.1250        0.50  \n",
       "28    0.500000  0.666667   -0.1250        0.50  \n",
       "29    1.000000  1.000000    0.0000         inf  \n",
       "30    0.500000  1.000000    0.0000        1.00  \n",
       "31    1.000000  1.333333    0.0625         inf  \n",
       "32    0.500000  0.666667   -0.1250        0.50  \n",
       "33    0.500000  1.000000    0.0000        1.00  \n",
       "34    0.500000  1.000000    0.0000        1.00  \n",
       "35    1.000000  1.333333    0.0625         inf  \n",
       "36    0.500000  1.000000    0.0000        1.00  \n",
       "37    1.000000  1.000000    0.0000         inf  \n",
       "38    0.750000  1.000000    0.0000        1.00  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_rules(fpgrowth(df, min_support=0.1, use_colnames=True), metric='confidence', min_threshold=0.5, support_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monetary-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "second-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lonely-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prostate-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dried-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original rating data\n",
    "raw_data = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "                [np.NaN, 5, np.NaN, 3, 1],\n",
    "                [np.NaN, np.NaN, 3, 4, 4],\n",
    "                [5, 2, 1, 2, np.NaN]])\n",
    "user_num, item_num = raw_data.shape\n",
    "latent_k = 3\n",
    "\n",
    "#np.random.seed(4141)\n",
    "\n",
    "X = np.random.normal(scale=1./latent_k, size=(user_num, latent_k))\n",
    "Y = np.random.normal(scale=1./latent_k, size=(item_num, latent_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "warming-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(scale=1./latent_k, size=(user_num, latent_k))\n",
    "Y = np.random.normal(scale=1./latent_k, size=(item_num, latent_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fatal-wednesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1855684 ,  0.60394651,  0.65685723,  0.24202688, -0.2266571 ],\n",
       "       [-0.31839767,  0.37288138, -0.04347289,  0.16462162, -0.18338114],\n",
       "       [-0.38159811, -0.22793813, -0.0188598 , -0.26128756,  0.00746197]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "freelance-preparation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11254811, -0.1017116 , -0.07186635, -0.07822132,  0.01957929],\n",
       "       [-0.06399175,  0.23480004,  0.26885289,  0.04820602, -0.11489314],\n",
       "       [ 0.04887933,  0.24511832,  0.11567939,  0.13961186, -0.08417141],\n",
       "       [-0.09357404, -0.12558656, -0.15124502, -0.06227756,  0.03802207]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "rotary-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(raw_data, X, Y, non_zeros):\n",
    "    error = 0\n",
    "    # 두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(X, Y.T)\n",
    "    \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    raw_data_non_zeros = raw_data[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "      \n",
    "    mse = mean_squared_error(raw_data_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "active-comfort",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  0  rmse :  3.271698689472804\n",
      "### iteration step :  50  rmse :  0.5807101443828643\n",
      "### iteration step :  100  rmse :  0.18214232690830423\n",
      "### iteration step :  150  rmse :  0.09383431840583815\n",
      "### iteration step :  200  rmse :  0.060199422013415875\n",
      "### iteration step :  250  rmse :  0.04289500863158748\n",
      "### iteration step :  300  rmse :  0.032697888660916226\n",
      "### iteration step :  350  rmse :  0.02630177615270153\n",
      "### iteration step :  400  rmse :  0.022206692684498403\n",
      "### iteration step :  450  rmse :  0.019584032625695143\n",
      "### iteration step :  500  rmse :  0.01791532243255158\n",
      "### iteration step :  550  rmse :  0.01685940549514744\n",
      "### iteration step :  600  rmse :  0.016191481163998482\n",
      "### iteration step :  650  rmse :  0.015766344660999066\n",
      "### iteration step :  700  rmse :  0.015492291016782319\n",
      "### iteration step :  750  rmse :  0.01531235391711345\n",
      "### iteration step :  800  rmse :  0.01519144940686766\n",
      "### iteration step :  850  rmse :  0.015107999634216506\n",
      "### iteration step :  900  rmse :  0.015048673111521678\n",
      "### iteration step :  950  rmse :  0.01500515702837396\n",
      "### iteration step :  1000  rmse :  0.0149722007921236\n",
      "### iteration step :  1050  rmse :  0.01494643562266855\n",
      "### iteration step :  1100  rmse :  0.014925661721045558\n",
      "### iteration step :  1150  rmse :  0.01490841556773404\n",
      "### iteration step :  1200  rmse :  0.014893704977438497\n",
      "### iteration step :  1250  rmse :  0.014880844963536043\n",
      "### iteration step :  1300  rmse :  0.014869354586868793\n",
      "### iteration step :  1350  rmse :  0.01485889104916819\n",
      "### iteration step :  1400  rmse :  0.01484920681059989\n",
      "### iteration step :  1450  rmse :  0.014840121149299636\n",
      "### iteration step :  1500  rmse :  0.014831500931920387\n",
      "### iteration step :  1550  rmse :  0.014823247367247416\n",
      "### iteration step :  1600  rmse :  0.014815286721608568\n",
      "### iteration step :  1650  rmse :  0.014807563709120824\n",
      "### iteration step :  1700  rmse :  0.014800036722227036\n",
      "### iteration step :  1750  rmse :  0.014792674350827421\n",
      "### iteration step :  1800  rmse :  0.014785452818080169\n",
      "### iteration step :  1850  rmse :  0.014778354077341602\n",
      "### iteration step :  1900  rmse :  0.014771364391549446\n",
      "### iteration step :  1950  rmse :  0.014764473268024015\n",
      "### iteration step :  2000  rmse :  0.014757672657152119\n",
      "### iteration step :  2050  rmse :  0.014750956348193218\n",
      "### iteration step :  2100  rmse :  0.01474431951302417\n",
      "### iteration step :  2150  rmse :  0.014737758361318245\n",
      "### iteration step :  2200  rmse :  0.014731269879884363\n",
      "### iteration step :  2250  rmse :  0.014724851635675548\n",
      "### iteration step :  2300  rmse :  0.01471850162704924\n",
      "### iteration step :  2350  rmse :  0.014712218171598745\n",
      "### iteration step :  2400  rmse :  0.014705999821739077\n",
      "### iteration step :  2450  rmse :  0.014699845301329117\n",
      "### iteration step :  2500  rmse :  0.014693753458255274\n",
      "### iteration step :  2550  rmse :  0.014687723229106239\n",
      "### iteration step :  2600  rmse :  0.01468175361299821\n",
      "### iteration step :  2650  rmse :  0.014675843652324378\n",
      "### iteration step :  2700  rmse :  0.014669992418720626\n",
      "### iteration step :  2750  rmse :  0.014664199002966768\n",
      "### iteration step :  2800  rmse :  0.014658462507843023\n",
      "### iteration step :  2850  rmse :  0.014652782043186277\n",
      "### iteration step :  2900  rmse :  0.01464715672260137\n",
      "### iteration step :  2950  rmse :  0.014641585661381415\n",
      "### iteration step :  3000  rmse :  0.014636067975329375\n",
      "### iteration step :  3050  rmse :  0.014630602780227802\n",
      "### iteration step :  3100  rmse :  0.014625189191774359\n",
      "### iteration step :  3150  rmse :  0.014619826325846854\n",
      "### iteration step :  3200  rmse :  0.014614513298994871\n",
      "### iteration step :  3250  rmse :  0.014609249229080357\n",
      "### iteration step :  3300  rmse :  0.014604033236005443\n",
      "### iteration step :  3350  rmse :  0.01459886444249139\n",
      "### iteration step :  3400  rmse :  0.01459374197487599\n",
      "### iteration step :  3450  rmse :  0.014588664963908371\n",
      "### iteration step :  3500  rmse :  0.014583632545517769\n",
      "### iteration step :  3550  rmse :  0.014578643861561637\n",
      "### iteration step :  3600  rmse :  0.014573698060524028\n",
      "### iteration step :  3650  rmse :  0.014568794298181793\n",
      "### iteration step :  3700  rmse :  0.014563931738220945\n",
      "### iteration step :  3750  rmse :  0.01455910955280312\n",
      "### iteration step :  3800  rmse :  0.014554326923095764\n",
      "### iteration step :  3850  rmse :  0.014549583039746166\n",
      "### iteration step :  3900  rmse :  0.014544877103317984\n",
      "### iteration step :  3950  rmse :  0.014540208324681607\n",
      "### iteration step :  4000  rmse :  0.014535575925364985\n",
      "### iteration step :  4050  rmse :  0.014530979137865841\n",
      "### iteration step :  4100  rmse :  0.01452641720592469\n",
      "### iteration step :  4150  rmse :  0.014521889384764997\n",
      "### iteration step :  4200  rmse :  0.014517394941301862\n",
      "### iteration step :  4250  rmse :  0.014512933154314287\n",
      "### iteration step :  4300  rmse :  0.014508503314595918\n",
      "### iteration step :  4350  rmse :  0.014504104725072057\n",
      "### iteration step :  4400  rmse :  0.01449973670089727\n",
      "### iteration step :  4450  rmse :  0.014495398569524856\n",
      "### iteration step :  4500  rmse :  0.01449108967075685\n",
      "### iteration step :  4550  rmse :  0.014486809356775291\n",
      "### iteration step :  4600  rmse :  0.014482556992150068\n",
      "### iteration step :  4650  rmse :  0.014478331953834713\n",
      "### iteration step :  4700  rmse :  0.014474133631141282\n",
      "### iteration step :  4750  rmse :  0.014469961425706472\n",
      "### iteration step :  4800  rmse :  0.014465814751435149\n",
      "### iteration step :  4850  rmse :  0.014461693034443536\n",
      "### iteration step :  4900  rmse :  0.014457595712977254\n",
      "### iteration step :  4950  rmse :  0.014453522237330717\n",
      "### iteration step :  5000  rmse :  0.0144494720697509\n",
      "### iteration step :  5050  rmse :  0.014445444684330698\n",
      "### iteration step :  5100  rmse :  0.014441439566899337\n",
      "### iteration step :  5150  rmse :  0.014437456214905093\n",
      "### iteration step :  5200  rmse :  0.014433494137286399\n",
      "### iteration step :  5250  rmse :  0.014429552854342737\n",
      "### iteration step :  5300  rmse :  0.014425631897597076\n",
      "### iteration step :  5350  rmse :  0.0144217308096552\n",
      "### iteration step :  5400  rmse :  0.014417849144060642\n",
      "### iteration step :  5450  rmse :  0.014413986465146024\n",
      "### iteration step :  5500  rmse :  0.014410142347880423\n",
      "### iteration step :  5550  rmse :  0.014406316377716243\n",
      "### iteration step :  5600  rmse :  0.014402508150430374\n",
      "### iteration step :  5650  rmse :  0.014398717271966956\n",
      "### iteration step :  5700  rmse :  0.014394943358277328\n",
      "### iteration step :  5750  rmse :  0.01439118603515757\n",
      "### iteration step :  5800  rmse :  0.0143874449380861\n",
      "### iteration step :  5850  rmse :  0.014383719712060483\n",
      "### iteration step :  5900  rmse :  0.014380010011435561\n",
      "### iteration step :  5950  rmse :  0.014376315499759212\n",
      "### iteration step :  6000  rmse :  0.014372635849606881\n",
      "### iteration step :  6050  rmse :  0.01436897074241943\n",
      "### iteration step :  6100  rmse :  0.014365319868343294\n",
      "### iteration step :  6150  rmse :  0.014361682926063036\n",
      "### iteration step :  6200  rmse :  0.014358059622644928\n",
      "### iteration step :  6250  rmse :  0.014354449673373567\n",
      "### iteration step :  6300  rmse :  0.014350852801595027\n",
      "### iteration step :  6350  rmse :  0.014347268738554304\n",
      "### iteration step :  6400  rmse :  0.014343697223245326\n",
      "### iteration step :  6450  rmse :  0.014340138002248166\n",
      "### iteration step :  6500  rmse :  0.014336590829580982\n",
      "### iteration step :  6550  rmse :  0.014333055466545478\n",
      "### iteration step :  6600  rmse :  0.014329531681575258\n",
      "### iteration step :  6650  rmse :  0.01432601925008822\n",
      "### iteration step :  6700  rmse :  0.01432251795434035\n",
      "### iteration step :  6750  rmse :  0.014319027583278689\n",
      "### iteration step :  6800  rmse :  0.014315547932396571\n",
      "### iteration step :  6850  rmse :  0.014312078803595207\n",
      "### iteration step :  6900  rmse :  0.014308620005043595\n",
      "### iteration step :  6950  rmse :  0.014305171351038674\n",
      "### iteration step :  7000  rmse :  0.014301732661871984\n",
      "### iteration step :  7050  rmse :  0.01429830376369362\n",
      "### iteration step :  7100  rmse :  0.01429488448838234\n",
      "### iteration step :  7150  rmse :  0.014291474673417723\n",
      "### iteration step :  7200  rmse :  0.014288074161747233\n",
      "### iteration step :  7250  rmse :  0.014284682801666646\n",
      "### iteration step :  7300  rmse :  0.014281300446693308\n",
      "### iteration step :  7350  rmse :  0.01427792695544301\n",
      "### iteration step :  7400  rmse :  0.014274562191517605\n",
      "### iteration step :  7450  rmse :  0.014271206023378512\n",
      "### iteration step :  7500  rmse :  0.014267858324239019\n",
      "### iteration step :  7550  rmse :  0.01426451897194524\n",
      "### iteration step :  7600  rmse :  0.014261187848869828\n",
      "### iteration step :  7650  rmse :  0.014257864841800107\n",
      "### iteration step :  7700  rmse :  0.014254549841829752\n",
      "### iteration step :  7750  rmse :  0.014251242744254147\n",
      "### iteration step :  7800  rmse :  0.01424794344846938\n",
      "### iteration step :  7850  rmse :  0.014244651857867295\n",
      "### iteration step :  7900  rmse :  0.014241367879737371\n",
      "### iteration step :  7950  rmse :  0.01423809142516927\n",
      "### iteration step :  8000  rmse :  0.014234822408956141\n",
      "### iteration step :  8050  rmse :  0.014231560749501923\n",
      "### iteration step :  8100  rmse :  0.014228306368725872\n",
      "### iteration step :  8150  rmse :  0.014225059191977002\n",
      "### iteration step :  8200  rmse :  0.014221819147941545\n",
      "### iteration step :  8250  rmse :  0.014218586168556048\n",
      "### iteration step :  8300  rmse :  0.014215360188924536\n",
      "### iteration step :  8350  rmse :  0.014212141147233051\n",
      "### iteration step :  8400  rmse :  0.014208928984668679\n",
      "### iteration step :  8450  rmse :  0.014205723645336867\n",
      "### iteration step :  8500  rmse :  0.01420252507618765\n",
      "### iteration step :  8550  rmse :  0.014199333226934\n",
      "### iteration step :  8600  rmse :  0.014196148049977432\n",
      "### iteration step :  8650  rmse :  0.014192969500334215\n",
      "### iteration step :  8700  rmse :  0.014189797535565271\n",
      "### iteration step :  8750  rmse :  0.014186632115700048\n",
      "### iteration step :  8800  rmse :  0.014183473203173006\n",
      "### iteration step :  8850  rmse :  0.01418032076274907\n",
      "### iteration step :  8900  rmse :  0.014177174761463105\n",
      "### iteration step :  8950  rmse :  0.01417403516854809\n",
      "### iteration step :  9000  rmse :  0.01417090195538023\n",
      "### iteration step :  9050  rmse :  0.014167775095405559\n",
      "### iteration step :  9100  rmse :  0.014164654564086464\n",
      "### iteration step :  9150  rmse :  0.01416154033883885\n",
      "### iteration step :  9200  rmse :  0.014158432398972265\n",
      "### iteration step :  9250  rmse :  0.014155330725635372\n",
      "### iteration step :  9300  rmse :  0.014152235301756544\n",
      "### iteration step :  9350  rmse :  0.014149146111990805\n",
      "### iteration step :  9400  rmse :  0.01414606314266408\n",
      "### iteration step :  9450  rmse :  0.01414298638172335\n",
      "### iteration step :  9500  rmse :  0.014139915818681393\n",
      "### iteration step :  9550  rmse :  0.01413685144456714\n",
      "### iteration step :  9600  rmse :  0.014133793251879486\n",
      "### iteration step :  9650  rmse :  0.014130741234533915\n",
      "### iteration step :  9700  rmse :  0.014127695387816984\n",
      "### iteration step :  9750  rmse :  0.014124655708344036\n",
      "### iteration step :  9800  rmse :  0.01412162219400663\n",
      "### iteration step :  9850  rmse :  0.014118594843932273\n",
      "### iteration step :  9900  rmse :  0.014115573658441313\n",
      "### iteration step :  9950  rmse :  0.014112558639004085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd3d00b9b50>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장. \n",
    "non_zeros = [ (i, j, raw_data[i,j]) for i in range(user_num) for j in range(item_num) if raw_data[i,j] > 0 ]\n",
    "# 아래 식과 똑같은 식임\n",
    "# non_zeroes=[]\n",
    "# for j in range(num_items) :\n",
    "#     for i in range(num_users):\n",
    "#         if R[i, j] > 0:\n",
    "#             non_zeros\n",
    "    \n",
    "steps=10000\n",
    "learning_rate=0.01\n",
    "r_lambda=0.01\n",
    "rmse_list = []\n",
    "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros:\n",
    "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        e_ij = r - np.dot(X[i, :], Y[j, :].T)\n",
    "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "        X[i,:] = X[i,:] + learning_rate*(e_ij * Y[j, :] - r_lambda*X[i,:])\n",
    "        Y[j,:] = Y[j,:] + learning_rate*(e_ij * X[i, :] - r_lambda*Y[j,:])\n",
    "\n",
    "    rmse = get_rmse(raw_data, X, Y, non_zeros)\n",
    "    if (step % 50) == 0 :\n",
    "        rmse_list.append(rmse)\n",
    "        print(\"### iteration step : \", step,\" rmse : \", rmse)\n",
    "plt.plot(range(1,201), rmse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ready-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict matrix : \n",
      " [[3.992 2.235 1.218 1.995 2.367]\n",
      " [1.987 4.979 2.402 2.988 1.011]\n",
      " [5.78  4.852 2.985 3.983 3.982]\n",
      " [4.975 1.995 1.009 2.    2.797]]\n"
     ]
    }
   ],
   "source": [
    "pred_matrix = np.dot(X, Y.T)\n",
    "print('predict matrix : \\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "demographic-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(raw_data, latent_k, steps=200, learning_rate=0.01, r_lambda = 0.01):\n",
    "    user_num, item_num = raw_data.shape\n",
    "    np.random.seed(4141)\n",
    "    X = np.random.normal(scale=1./latent_k, size=(user_num, latent_k))\n",
    "    Y = np.random.normal(scale=1./latent_k, size=(item_num, latent_k))\n",
    "    \n",
    "    break_count = 0\n",
    "    non_zeros = [(i,j, raw_data[i,j]) for i in range(user_num) for j in range(item_num) if raw_data[i,j] > 0]\n",
    "    \n",
    "    for step in range(steps):\n",
    "        for i, j, r in non_zeros:\n",
    "            e_ij = r - np.dot(X[i, :], Y[j, :].T)\n",
    "            \n",
    "            X[i, :] = X[i,:] + learning_rate*(e_ij * Y[j, :] - r_lambda*X[i, :])\n",
    "            Y[j, :] = Y[j,:] + learning_rate*(e_ij * X[i, :] - r_lambda*Y[j, :])\n",
    "        \n",
    "        rmse = get_rmse(raw_data, X, Y, non_zeros)\n",
    "        if (step % 10) == 0:\n",
    "            print(\"=====iteration step : \", step, \"rmse\", rmse)\n",
    "    \n",
    "    return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "driven-formation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====iteration step :  0 rmse 3.2146278229053546\n",
      "=====iteration step :  10 rmse 2.865850010873045\n",
      "=====iteration step :  20 rmse 1.993686307230116\n",
      "=====iteration step :  30 rmse 1.0276620490396489\n",
      "=====iteration step :  40 rmse 0.5925110964719479\n",
      "=====iteration step :  50 rmse 0.41384596000010193\n",
      "=====iteration step :  60 rmse 0.3154788420666948\n",
      "=====iteration step :  70 rmse 0.25129117908855103\n",
      "=====iteration step :  80 rmse 0.20573812609289277\n",
      "=====iteration step :  90 rmse 0.1714976868227991\n",
      "=====iteration step :  100 rmse 0.1445908297905475\n",
      "=====iteration step :  110 rmse 0.12276644939294312\n",
      "=====iteration step :  120 rmse 0.10470906084852459\n",
      "=====iteration step :  130 rmse 0.08960312452932685\n",
      "=====iteration step :  140 rmse 0.07689965105834697\n",
      "=====iteration step :  150 rmse 0.06619678574551839\n",
      "=====iteration step :  160 rmse 0.05718039724460276\n",
      "=====iteration step :  170 rmse 0.0495943779044854\n",
      "=====iteration step :  180 rmse 0.043225009376968326\n",
      "=====iteration step :  190 rmse 0.0378918108579366\n"
     ]
    }
   ],
   "source": [
    "X, Y = matrix_factorization(raw_data, latent_k = 3, steps = 200, learning_rate = 0.01, r_lambda = 0.01)\n",
    "pred_matrix = np.dot(X, Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "analyzed-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.01989097, 1.68440105, 1.22882015, 1.92809119, 2.16028945],\n",
       "       [0.57683234, 4.99042048, 1.85921439, 2.95699045, 1.02457235],\n",
       "       [4.27955336, 4.47650881, 2.97137324, 4.01560945, 3.97042663],\n",
       "       [4.95823665, 1.97585265, 1.01986855, 2.03128373, 1.83155397]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fantastic-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3.0</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5.0</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3.0</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "0          196      242     3.0  881250949\n",
       "1          186      302     3.0  891717742\n",
       "2           22      377     1.0  878887116\n",
       "3          244       51     2.0  880606923\n",
       "4          166      346     1.0  886397596\n",
       "...        ...      ...     ...        ...\n",
       "99995      880      476     3.0  880175444\n",
       "99996      716      204     5.0  879795543\n",
       "99997      276     1090     1.0  874795795\n",
       "99998       13      225     2.0  882399156\n",
       "99999       12      203     3.0  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Linux/Data/recommendation/ml-100k.zip')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "reduced-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviematrix = df.pivot_table(index=\"user_id\",columns=\"item_id\",values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "naughty-broadcast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "user_id                                                              ...   \n",
      "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
      "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "5         4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   \n",
      "940       NaN   NaN   NaN   2.0   NaN   NaN   4.0   5.0   3.0   NaN  ...   \n",
      "941       5.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   \n",
      "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "943       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN  ...   \n",
      "\n",
      "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "user_id                                                              \n",
      "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "940       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "941       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "943       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[943 rows x 1682 columns] (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "print(moviematrix, moviematrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "balanced-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original rating data\n",
    "raw_data = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "                [np.NaN, 5, np.NaN, 3, 1],\n",
    "                [np.NaN, np.NaN, 3, 4, 4],\n",
    "                [5, 2, 1, 2, np.NaN]])\n",
    "user_num, item_num = raw_data.shape\n",
    "latent_k = 3\n",
    "\n",
    "#np.random.seed(4141)\n",
    "\n",
    "X = np.random.normal(scale=1./latent_k, size=(user_num, latent_k))\n",
    "Y = np.random.normal(scale=1./latent_k, size=(item_num, latent_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "billion-parks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviematrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "engaging-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num, item_num = movie_matrix.shape\n",
    "latent_k = 50\n",
    "\n",
    "X = np.random.normal(scale=1./latent_k, size=(user_num, latent_k))\n",
    "Y = np.random.normal(scale=1./latent_k, size=(item_num, latent_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "proof-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(movie_matrix, X, Y, non_zeros):\n",
    "    error = 0\n",
    "    full_pred_matrix = np.dot(X, Y.T)\n",
    "    \n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    movie_matrix_non_zeros = movie_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    \n",
    "    mse = mean_squared_error(movie_matrix_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "charming-smart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict matrix : \n",
      " [[-0.001  0.     0.002 ...  0.003 -0.001 -0.006]\n",
      " [ 0.     0.002  0.002 ... -0.001 -0.     0.002]\n",
      " [-0.003 -0.002 -0.001 ... -0.001  0.004 -0.001]\n",
      " ...\n",
      " [ 0.006  0.001 -0.002 ... -0.003 -0.001 -0.001]\n",
      " [ 0.005  0.002 -0.002 ... -0.005 -0.004  0.005]\n",
      " [ 0.002 -0.001 -0.    ... -0.001 -0.006  0.001]]\n"
     ]
    }
   ],
   "source": [
    "pred_matrix = np.dot(X, Y.T)\n",
    "print('predict matrix : \\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "concerned-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df.values, test_size = 0.2, random_state=419)\n",
    "train = pd.DataFrame(train, columns = df.columns)\n",
    "test = pd.DataFrame(test, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "subtle-lease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size  :  80000\n",
      "Test Size :  20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Size  : \", len(train))\n",
    "print(\"Test Size : \", len (test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "disturbed-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_user = ppp.LabelEncoder()\n",
    "le_item = ppp.LabelEncoder()\n",
    "train['user_id_idx'] = le_user.fit_transform(train['user_id'].values)\n",
    "train['item_id_idx'] = le_item.fit_transform(train['item_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "heard-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_ids = train['user_id'].unique()\n",
    "train_item_ids = train['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "stunning-sheffield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1660\n"
     ]
    }
   ],
   "source": [
    "print(len(train_user_ids), len(train_item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fallen-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19975\n"
     ]
    }
   ],
   "source": [
    "test = test[(test['user_id'].isin(train_user_ids)) & (test['item_id'].isin(train_item_ids))]\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "simple-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['user_id_idx'] = le_user.transform(test['user_id'].values)\n",
    "test['item_id_idx'] = le_item.transform(test['item_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "industrial-revelation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Users :  943\n",
      "Number of unique Items :  1660\n"
     ]
    }
   ],
   "source": [
    "n_users = train['user_id_idx'].nunique()\n",
    "n_items = train['item_id_idx'].nunique()\n",
    "print(\"Number of Unique Users : \", n_users)\n",
    "print(\"Number of unique Items : \", n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "resident-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num, item_num = movie_matrix.shape\n",
    "latent_k = 50\n",
    "\n",
    "X = np.random.normal(scale=1./latent_k, size=(user_num, latent_k))\n",
    "Y = np.random.normal(scale=1./latent_k, size=(item_num, latent_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "mental-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(movie_matrix, X, Y, non_zeros):\n",
    "    error = 0\n",
    "    full_pred_matrix = np.dot(X, Y.T)\n",
    "    \n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    movie_matrix_non_zeros = movie_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    \n",
    "    mse = mean_squared_error(movie_matrix_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "polish-layer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1682])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x_torch, y_torch.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "atomic-birthday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9435, 3.0802, 3.6955,  ..., 1.0778, 1.6759, 2.7843],\n",
       "        [3.7993, 3.6894, 3.0607,  ..., 1.0362, 2.2115, 2.7311],\n",
       "        [2.9624, 2.7220, 4.2034,  ..., 1.0090, 0.8372, 1.8126],\n",
       "        ...,\n",
       "        [4.9478, 3.9631, 2.3471,  ..., 1.2615, 1.5835, 2.4601],\n",
       "        [3.4425, 3.8860, 4.2708,  ..., 1.1751, 1.8658, 2.1853],\n",
       "        [3.1494, 4.7582, 2.9639,  ..., 1.3013, 1.9389, 2.3040]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x_torch, y_torch.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "atlantic-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(movie_matrix, X, Y, non_zeros):\n",
    "   # error = 0\n",
    "    full_pred_matrix = torch.matmul(x_torch, y_torch.T)\n",
    "    \n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    movie_matrix_non_zeros = movie_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    movie_matrix_non_zeros = torch.from_numpy(movie_matrix_non_zeros)\n",
    "\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    \n",
    "    mse = (full_pred_matrix_non_zeros - movie_matrix_non_zeros).pow(2).sum()\n",
    "    rmse = torch.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "adopted-tender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(792.8683, dtype=torch.float64)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(movie_matrix, x_torch, y_torch, non_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "typical-template",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9282.3454, dtype=torch.float64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pred_matrix = torch.matmul(x_torch, y_torch.T)\n",
    "x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "movie_matrix_non_zeros = movie_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "movie_matrix_non_zeros = torch.from_numpy(movie_matrix_non_zeros)\n",
    "full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "mse = (full_pred_matrix_non_zeros - movie_matrix_non_zeros).pow(2).sum()\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
